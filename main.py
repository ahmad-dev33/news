
import os
import requests
from bs4 import BeautifulSoup
from telegram import Bot, ParseMode
import json
from datetime import datetime
import time
import random
import re

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
if not os.path.exists('data'):
    os.makedirs('data')

CONFIG = {
    'sent_links_file': 'data/sent_links.json',
    'log_file': 'data/bot_log.txt',
    'sources': {
        'aljazeera': {
            'name': 'Ø§Ù„Ø¬Ø²ÙŠØ±Ø© Ù†Øª',
            'url': 'https://www.aljazeera.net',
            'selectors': {
                'container': 'article, .featured-news-item, .news-card, .gc__content',
                'title': 'h1, h2, h3, .title, .gc__title a',
                'link': 'a'
            },
            'enabled': True
        },
        'bbc_arabic': {
            'name': 'Ø¨ÙŠ Ø¨ÙŠ Ø³ÙŠ Ø¹Ø±Ø¨ÙŠ',
            'url': 'https://www.bbc.com/arabic',
            'selectors': {
                'container': 'article, .media-list__item, .block-link',
                'title': 'h3, .media__title, .block-link__overlay-text',
                'link': 'a'
            },
            'enabled': True
        },
        'rt_arabic': {
            'name': 'Ø±ÙˆØ³ÙŠØ§ Ø§Ù„ÙŠÙˆÙ…',
            'url': 'https://arabic.rt.com',
            'selectors': {
                'container': 'article, .card, .list-item',
                'title': 'h2, h3, .card__heading, .list-item__title',
                'link': 'a'
            },
            'enabled': True
        }
    }
}

class NewsBot:
    def __init__(self):
        try:
            self.bot = Bot(token=os.getenv('TELEGRAM_TOKEN')) if os.getenv('TELEGRAM_TOKEN') else None
            self.chat_id = os.getenv('CHAT_ID')
            self.hf_token = os.getenv('HUGGING_FACE_TOKEN')
        except:
            self.bot = None
            self.chat_id = None
            self.hf_token = None
        self.load_sent_links()

    def log(self, message):
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙÙŠ Ù…Ù„Ù log"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = f"[{timestamp}] {message}\n"
        try:
            with open(CONFIG['log_file'], 'a', encoding='utf-8') as f:
                f.write(log_entry)
        except:
            pass
        print(log_entry.strip())

    def load_sent_links(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø±Ø³Ù„Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹"""
        try:
            with open(CONFIG['sent_links_file'], 'r', encoding='utf-8') as f:
                self.sent_links = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            self.sent_links = []
            self.log("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯")

    def save_links(self):
        """Ø­ÙØ¸ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø±Ø³Ù„Ø©"""
        try:
            with open(CONFIG['sent_links_file'], 'w', encoding='utf-8') as f:
                json.dump(self.sent_links[-1000:], f)  # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 1000 Ø±Ø§Ø¨Ø· ÙÙ‚Ø·
        except:
            pass

    def is_syria_related(self, title):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø®Ø¨Ø± Ø¨Ø³ÙˆØ±ÙŠØ§"""
        syria_keywords = [
            'Ø³ÙˆØ±ÙŠØ§', 'Ø³ÙˆØ±ÙŠØ©', 'Ø¯Ù…Ø´Ù‚', 'Ø­Ù„Ø¨', 'Ø­Ù…Øµ', 'Ø­Ù…Ø§Ø©', 'Ø§Ù„Ù„Ø§Ø°Ù‚ÙŠØ©', 'Ø·Ø±Ø·ÙˆØ³',
            'Ø¯Ø±Ø¹Ø§', 'Ø§Ù„Ø³ÙˆÙŠØ¯Ø§Ø¡', 'Ø§Ù„Ù‚Ø§Ù…Ø´Ù„ÙŠ', 'Ø§Ù„Ø­Ø³ÙƒØ©', 'Ø¥Ø¯Ù„Ø¨', 'Ø§Ù„Ø±Ù‚Ø©', 'Ø¯ÙŠØ± Ø§Ù„Ø²ÙˆØ±',
            'Ø¨Ø´Ø§Ø± Ø§Ù„Ø£Ø³Ø¯', 'Ø§Ù„Ø£Ø³Ø¯', 'Ù†Ø¸Ø§Ù… Ø¯Ù…Ø´Ù‚', 'Ø§Ù„Ù…Ø¹Ø§Ø±Ø¶Ø© Ø§Ù„Ø³ÙˆØ±ÙŠØ©', 'Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø³ÙˆØ±ÙŠØ©',
            'Ø§Ù„Ù„Ø§Ø¬Ø¦ÙŠÙ† Ø§Ù„Ø³ÙˆØ±ÙŠÙŠÙ†', 'Ø§Ù„Ù†Ø§Ø²Ø­ÙŠÙ† Ø§Ù„Ø³ÙˆØ±ÙŠÙŠÙ†', 'Ù‡ÙŠØ¦Ø© ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…', 'Ø§Ù„Ø¬ÙŠØ´ Ø§Ù„Ø­Ø±',
            'Ù‚ÙˆØ§Øª Ø³ÙˆØ±ÙŠØ§ Ø§Ù„Ø¯ÙŠÙ…Ù‚Ø±Ø§Ø·ÙŠØ©', 'ÙƒØ±Ø¯Ø³ØªØ§Ù† Ø³ÙˆØ±ÙŠØ§', 'Ø´Ù…Ø§Ù„ Ø´Ø±Ù‚ Ø³ÙˆØ±ÙŠØ§'
        ]
        
        title_lower = title.lower()
        return any(keyword in title_lower for keyword in syria_keywords)

    def get_random_headers(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ headers Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¸Ø±"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15'
        ]
        
        return {
            'User-Agent': random.choice(user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ar,en-US;q=0.7,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }

    def generate_summary(self, title, content):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆØ¬Ø² Ù„Ù„Ø®Ø¨Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Hugging Face"""
        if not self.hf_token:
            return "Ù…ÙˆØ¬Ø² ØºÙŠØ± Ù…ØªÙˆÙØ± - ÙŠØªØ·Ù„Ø¨ ØªÙˆÙƒÙ† Hugging Face"
        
        try:
            headers = {
                "Authorization": f"Bearer {self.hf_token}",
                "Content-Type": "application/json"
            }
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ø®ÙŠØµ Ø¹Ø±Ø¨ÙŠ
            api_url = "https://api-inference.huggingface.co/models/aubmindlab/bert-base-arabertv02"
            
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†Øµ Ù„Ù„ØªÙ„Ø®ÙŠØµ
            text_to_summarize = f"{title}. {content[:500]}"  # Ø£ÙˆÙ„ 500 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            
            payload = {
                "inputs": text_to_summarize,
                "parameters": {
                    "max_length": 100,
                    "min_length": 30,
                    "do_sample": False
                }
            }
            
            response = requests.post(api_url, headers=headers, json=payload, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    return result[0].get('summary_text', title[:100] + "...")
                else:
                    return title[:100] + "..."
            else:
                self.log(f"Ø®Ø·Ø£ ÙÙŠ Hugging Face API: {response.status_code}")
                return title[:100] + "..."
                
        except Exception as e:
            self.log(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ø²: {str(e)}")
            return title[:100] + "..."

    def get_article_content(self, url):
        """Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ø²"""
        try:
            headers = self.get_random_headers()
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
            content_selectors = [
                'article p', '.article-content p', '.content p', 
                '.story-body p', '.post-content p', 'main p'
            ]
            
            content = ""
            for selector in content_selectors:
                paragraphs = soup.select(selector)
                if paragraphs:
                    content = " ".join([p.get_text(strip=True) for p in paragraphs[:3]])
                    if len(content) > 100:
                        break
            
            return content[:800] if content else ""
            
        except Exception as e:
            self.log(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„: {str(e)}")
            return ""

    def fetch_news(self, source_key):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ù…ØµØ¯Ø± Ù…Ø¹ÙŠÙ† Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø³ÙˆØ±ÙŠØ§"""
        if source_key not in CONFIG['sources'] or not CONFIG['sources'][source_key]['enabled']:
            return []

        config = CONFIG['sources'][source_key]
        headers = self.get_random_headers()
        headers['Referer'] = config['url']

        try:
            time.sleep(random.uniform(0.5, 2.0))
            
            session = requests.Session()
            response = session.get(config['url'], headers=headers, timeout=15, verify=True)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            news_items = []
            containers = soup.select(config['selectors']['container'])
            
            self.log(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(containers)} Ø¹Ù†ØµØ± Ù…Ù† {config['name']}")
            
            for article in containers[:100]:  # ÙØ­Øµ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ± Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± Ø³ÙˆØ±ÙŠØ§
                try:
                    title_element = article.select_one(config['selectors']['title'])
                    link_element = article.select_one(config['selectors']['link']) or article
                    
                    if not title_element:
                        continue
                        
                    title = title_element.get_text(strip=True)
                    link = link_element.get('href') if link_element else None
                    
                    if not title or not link or len(title) < 15:
                        continue

                    # ØªØµØ­ÙŠØ­ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù†Ø³Ø¨ÙŠØ©
                    if link.startswith('/'):
                        link = config['url'].rstrip('/') + link
                    elif not link.startswith('http'):
                        link = config['url'].rstrip('/') + '/' + link.lstrip('/')

                    # ØªØµÙÙŠØ© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
                    if any(exclude in link.lower() for exclude in ['javascript:', 'mailto:', '#']):
                        continue

                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø®Ø¨Ø± Ø¨Ø³ÙˆØ±ÙŠØ§
                    if self.is_syria_related(title) and link not in self.sent_links:
                        # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ø²
                        content = self.get_article_content(link)
                        summary = self.generate_summary(title, content)
                        
                        news_items.append({
                            'title': title[:200],
                            'link': link,
                            'source': config['name'],
                            'summary': summary,
                            'content_preview': content[:200] if content else ""
                        })
                        
                        self.sent_links.append(link)
                        self.log(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø®Ø¨Ø± Ø³ÙˆØ±ÙŠ: {title[:50]}...")
                        
                        if len(news_items) >= 5:  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø³ÙˆØ±ÙŠØ©
                            break

                except Exception as e:
                    continue

            self.log(f"ØªÙ… Ø¬Ù„Ø¨ {len(news_items)} Ø®Ø¨Ø± Ø³ÙˆØ±ÙŠ Ù…Ù† {config['name']}")
            return news_items

        except requests.exceptions.RequestException as e:
            self.log(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ {config['name']}: {str(e)}")
            return []
        except Exception as e:
            self.log(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† {config['name']}: {str(e)}")
            return []

    def get_all_news(self):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø³ÙˆØ±ÙŠØ§"""
        all_news = {}
        
        for source_key, source_config in CONFIG['sources'].items():
            if source_config['enabled']:
                news = self.fetch_news(source_key)
                if news:
                    all_news[source_config['name']] = news
                
        return all_news

    def send_news_to_telegram(self):
        """Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ø¥Ù„Ù‰ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…"""
        if not self.bot or not self.chat_id:
            self.log("Ù„Ù… ÙŠØªÙ… ØªÙƒÙˆÙŠÙ† Ø¨ÙˆØª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­")
            return False

        all_news = self.get_all_news()
        sent_count = 0

        # Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ÙŠØ©
        welcome_message = "ğŸ‡¸ğŸ‡¾ <b>Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø³ÙˆØ±ÙŠØ©</b>\n\n"
        welcome_message += f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        welcome_message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

        try:
            self.bot.send_message(
                chat_id=self.chat_id,
                text=welcome_message,
                parse_mode=ParseMode.HTML
            )
            time.sleep(2)
        except Exception as e:
            self.log(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ÙŠØ©: {str(e)}")

        for source, news in all_news.items():
            if news:
                for item in news:
                    try:
                        message = f"ğŸ“° <b>{item['title']}</b>\n\n"
                        message += f"ğŸ“ <b>Ø§Ù„Ù…ÙˆØ¬Ø²:</b>\n{item['summary']}\n\n"
                        message += f"ğŸ”— <a href='{item['link']}'>Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯</a>\n\n"
                        message += f"ğŸ“¡ Ø§Ù„Ù…ØµØ¯Ø±: {source}"

                        self.bot.send_message(
                            chat_id=self.chat_id,
                            text=message,
                            parse_mode=ParseMode.HTML,
                            disable_web_page_preview=False
                        )
                        
                        sent_count += 1
                        self.log(f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø®Ø¨Ø± Ø³ÙˆØ±ÙŠ Ù…Ù† {source}")
                        time.sleep(3)  # ØªØ£Ø®ÙŠØ± Ø£Ø·ÙˆÙ„ Ø¨ÙŠÙ† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
                        
                    except Exception as e:
                        self.log(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø®Ø¨Ø± Ù…Ù† {source}: {str(e)}")
                        continue

        # Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø®ØªØ§Ù…ÙŠØ©
        if sent_count > 0:
            summary_message = f"âœ… <b>ØªÙ… Ø¥Ø±Ø³Ø§Ù„ {sent_count} Ø®Ø¨Ø± Ø³ÙˆØ±ÙŠ</b>\n\n"
            summary_message += "ğŸ“± Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø±ØŒ ØªØ§Ø¨Ø¹ Ø§Ù„Ù‚Ù†Ø§Ø©\n"
            summary_message += f"ğŸ• Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ§Ù„ÙŠ Ø®Ù„Ø§Ù„ Ø³Ø§Ø¹Ø©"
            
            try:
                self.bot.send_message(
                    chat_id=self.chat_id,
                    text=summary_message,
                    parse_mode=ParseMode.HTML
                )
            except Exception as e:
                self.log(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®ØªØ§Ù…ÙŠØ©: {str(e)}")

        self.save_links()
        return sent_count > 0

if __name__ == "__main__":
    bot = NewsBot()
    bot.log("Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø¨ÙˆØª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø³ÙˆØ±ÙŠØ©")
    result = bot.send_news_to_telegram()
    if result:
        bot.log("ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­")
    else:
        bot.log("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± Ø¬Ø¯ÙŠØ¯Ø© Ø£Ùˆ Ø­Ø¯Ø« Ø®Ø·Ø£")
